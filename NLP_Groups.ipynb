{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "import sys\n",
    "from IPython.display import HTML\n",
    "from matplotlib import pyplot as plt\n",
    "from celluloid import Camera\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "from IPython.display import HTML\n",
    "from matplotlib import pyplot as plt\n",
    "from celluloid import Camera\n",
    "import collections\n",
    "\n",
    "\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem.porter import *\n",
    "import numpy as np\n",
    "np.random.seed(2018)\n",
    "import nltk\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "emails_df = pd.read_csv('Data/emails_tokenized.csv')\n",
    "employee_df = pd.read_csv('Data/employees.csv')\n",
    "network_df = pd.read_csv('Data/network.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({nan: 51,\n",
       "         'Manager': 12,\n",
       "         'Employee': 34,\n",
       "         'Vice President': 21,\n",
       "         'Director': 12,\n",
       "         'Trader': 11,\n",
       "         'President': 4,\n",
       "         'CEO': 3,\n",
       "         'Managing Director': 2,\n",
       "         'In House Lawyer': 1})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emails_df = emails_df[~emails_df['token_subject'].isna()]\n",
    "\n",
    "exec_list = ['CEO','President','Vice President']\n",
    "\n",
    "job_count = collections.Counter()\n",
    "for rank in employee_df['job_rank']:\n",
    "    job_count[rank] +=1\n",
    "\n",
    "job_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stems = ['fw','draft','p','2001']\n",
    "\n",
    "emails_df['token_subject']= [ast.literal_eval(x) for x in emails_df['token_subject']]\n",
    "subjects = []\n",
    "for email in emails_df['token_subject']:\n",
    "    for stem in stems:\n",
    "        while stem in email:\n",
    "            email.remove(stem)\n",
    "    subjects.append(email)\n",
    "emails_df['token_subject'] = subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>mid</th>\n",
       "      <th>sender</th>\n",
       "      <th>date</th>\n",
       "      <th>message_id</th>\n",
       "      <th>subject</th>\n",
       "      <th>body</th>\n",
       "      <th>folder</th>\n",
       "      <th>cleaned_body</th>\n",
       "      <th>cleaned_subject</th>\n",
       "      <th>sender_level</th>\n",
       "      <th>token_body</th>\n",
       "      <th>token_subject</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24</td>\n",
       "      <td>76</td>\n",
       "      <td>mary.hain@enron.com</td>\n",
       "      <td>2000-08-17 07:11:00</td>\n",
       "      <td>&lt;5722839.1075863606028.JavaMail.evans@thyme&gt;</td>\n",
       "      <td>Enron s transmission/power exchange model for ...</td>\n",
       "      <td>---------------------- Forwarded by Mary Hain/...</td>\n",
       "      <td>Robert_Badeer_Aug2000Notes FoldersNotes inbox</td>\n",
       "      <td>enron s transmission/power exchange model for...</td>\n",
       "      <td>enron s transmission/power exchange model for ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[['enron', 'transmission/power', 'exchange', '...</td>\n",
       "      <td>[enron, transmission/power, exchange, model, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>41</td>\n",
       "      <td>93</td>\n",
       "      <td>cooper.richey@enron.com</td>\n",
       "      <td>2000-08-23 04:39:00</td>\n",
       "      <td>&lt;4083763.1075863605647.JavaMail.evans@thyme&gt;</td>\n",
       "      <td>Change to EnData</td>\n",
       "      <td>The Fundamentals Group is moving Database serv...</td>\n",
       "      <td>Robert_Badeer_Aug2000Notes FoldersNotes inbox</td>\n",
       "      <td>the fundamentals group is moving database serv...</td>\n",
       "      <td>change to endata</td>\n",
       "      <td>Manager</td>\n",
       "      <td>[['fundamentals', 'group', 'moving', 'database...</td>\n",
       "      <td>[change, endata]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>107</td>\n",
       "      <td>159</td>\n",
       "      <td>mary.hain@enron.com</td>\n",
       "      <td>2000-08-29 06:28:00</td>\n",
       "      <td>&lt;14457348.1075863603979.JavaMail.evans@thyme&gt;</td>\n",
       "      <td>ISO To Participate in Super Peak Market</td>\n",
       "      <td>FYI---------------------- Forwarded by Mary Ha...</td>\n",
       "      <td>Robert_Badeer_Aug2000Notes FoldersNotes inbox</td>\n",
       "      <td>iso to participate in super peak marketfolks,...</td>\n",
       "      <td>iso to participate in super peak  et</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[['iso', 'participate', 'super', 'peak', 'mark...</td>\n",
       "      <td>[iso, participate, super, peak, et]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>137</td>\n",
       "      <td>465</td>\n",
       "      <td>jeff.dasovich@enron.com</td>\n",
       "      <td>2000-08-07 12:23:00</td>\n",
       "      <td>&lt;769016.1075863596202.JavaMail.evans@thyme&gt;</td>\n",
       "      <td>CalPX Market Compliance Unit Submits its 2nd A...</td>\n",
       "      <td>FYI.  The report posted on the website fails t...</td>\n",
       "      <td>Robert_Badeer_Aug2000Notes FoldersCapx</td>\n",
       "      <td>calpx market compliance unit submits its 2nd ...</td>\n",
       "      <td>calpx  et compliance unit submits its 2nd annu...</td>\n",
       "      <td>Employee</td>\n",
       "      <td>[['calpx', 'market', 'compliance', 'unit', 'su...</td>\n",
       "      <td>[calpx, et, compliance, unit, submits, 2nd, an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>189</td>\n",
       "      <td>517</td>\n",
       "      <td>jeff.dasovich@enron.com</td>\n",
       "      <td>2000-08-10 03:12:00</td>\n",
       "      <td>&lt;28494229.1075863594884.JavaMail.evans@thyme&gt;</td>\n",
       "      <td>Re: Governor s Press Conference -- Shot Across...</td>\n",
       "      <td>There appears to be a pattern forming.  The ad...</td>\n",
       "      <td>Robert_Badeer_Aug2000Notes FoldersCalifornia</td>\n",
       "      <td>governor s press conference -- shot across th...</td>\n",
       "      <td>re: governor s press conference -- shot across...</td>\n",
       "      <td>Employee</td>\n",
       "      <td>[['governor', 'press', 'conference', '--', 'sh...</td>\n",
       "      <td>[governor, press, conference, --, shot, across...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Unnamed: 0  mid                   sender                 date  \\\n",
       "0         24   76      mary.hain@enron.com  2000-08-17 07:11:00   \n",
       "1         41   93  cooper.richey@enron.com  2000-08-23 04:39:00   \n",
       "2        107  159      mary.hain@enron.com  2000-08-29 06:28:00   \n",
       "3        137  465  jeff.dasovich@enron.com  2000-08-07 12:23:00   \n",
       "4        189  517  jeff.dasovich@enron.com  2000-08-10 03:12:00   \n",
       "\n",
       "                                      message_id  \\\n",
       "0   <5722839.1075863606028.JavaMail.evans@thyme>   \n",
       "1   <4083763.1075863605647.JavaMail.evans@thyme>   \n",
       "2  <14457348.1075863603979.JavaMail.evans@thyme>   \n",
       "3    <769016.1075863596202.JavaMail.evans@thyme>   \n",
       "4  <28494229.1075863594884.JavaMail.evans@thyme>   \n",
       "\n",
       "                                             subject  \\\n",
       "0  Enron s transmission/power exchange model for ...   \n",
       "1                                   Change to EnData   \n",
       "2            ISO To Participate in Super Peak Market   \n",
       "3  CalPX Market Compliance Unit Submits its 2nd A...   \n",
       "4  Re: Governor s Press Conference -- Shot Across...   \n",
       "\n",
       "                                                body  \\\n",
       "0  ---------------------- Forwarded by Mary Hain/...   \n",
       "1  The Fundamentals Group is moving Database serv...   \n",
       "2  FYI---------------------- Forwarded by Mary Ha...   \n",
       "3  FYI.  The report posted on the website fails t...   \n",
       "4  There appears to be a pattern forming.  The ad...   \n",
       "\n",
       "                                          folder  \\\n",
       "0  Robert_Badeer_Aug2000Notes FoldersNotes inbox   \n",
       "1  Robert_Badeer_Aug2000Notes FoldersNotes inbox   \n",
       "2  Robert_Badeer_Aug2000Notes FoldersNotes inbox   \n",
       "3         Robert_Badeer_Aug2000Notes FoldersCapx   \n",
       "4   Robert_Badeer_Aug2000Notes FoldersCalifornia   \n",
       "\n",
       "                                        cleaned_body  \\\n",
       "0   enron s transmission/power exchange model for...   \n",
       "1  the fundamentals group is moving database serv...   \n",
       "2   iso to participate in super peak marketfolks,...   \n",
       "3   calpx market compliance unit submits its 2nd ...   \n",
       "4   governor s press conference -- shot across th...   \n",
       "\n",
       "                                     cleaned_subject sender_level  \\\n",
       "0  enron s transmission/power exchange model for ...          NaN   \n",
       "1                                   change to endata      Manager   \n",
       "2               iso to participate in super peak  et          NaN   \n",
       "3  calpx  et compliance unit submits its 2nd annu...     Employee   \n",
       "4  re: governor s press conference -- shot across...     Employee   \n",
       "\n",
       "                                          token_body  \\\n",
       "0  [['enron', 'transmission/power', 'exchange', '...   \n",
       "1  [['fundamentals', 'group', 'moving', 'database...   \n",
       "2  [['iso', 'participate', 'super', 'peak', 'mark...   \n",
       "3  [['calpx', 'market', 'compliance', 'unit', 'su...   \n",
       "4  [['governor', 'press', 'conference', '--', 'sh...   \n",
       "\n",
       "                                       token_subject  \n",
       "0  [enron, transmission/power, exchange, model, d...  \n",
       "1                                   [change, endata]  \n",
       "2                [iso, participate, super, peak, et]  \n",
       "3  [calpx, et, compliance, unit, submits, 2nd, an...  \n",
       "4  [governor, press, conference, --, shot, across...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emails_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "emails_df['token_body']= [ast.literal_eval(x) for x in emails_df['token_body']]\n",
    "subjects = []\n",
    "for email in emails_df['token_body']:\n",
    "    sents = []\n",
    "    for sent in email:\n",
    "        for stem in stems:\n",
    "            while stem in sent:\n",
    "                sent.remove(stem)\n",
    "        sents.append(email)\n",
    "    subjects.append(sents)\n",
    "emails_df['token_body'] = subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_tokens = list(emails_df['token_subject']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = gensim.corpora.Dictionary(subject_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 discussion\n",
      "1 enron\n",
      "2 exchange\n",
      "3 model\n",
      "4 transmission/power\n",
      "5 change\n",
      "6 endata\n",
      "7 et\n",
      "8 iso\n",
      "9 participate\n",
      "10 peak\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for k, v in dictionary.iteritems():\n",
    "    print(k, v)\n",
    "    count += 1\n",
    "    if count > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary.filter_extremes(no_below=15, no_above=0.5, keep_n=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(421, 1), (474, 1), (820, 1)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_corpus = [dictionary.doc2bow(doc) for doc in subject_tokens]\n",
    "bow_corpus[4310]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.5546227871296954),\n",
      " (1, 0.3020901308523857),\n",
      " (2, 0.5623506333794593),\n",
      " (3, 0.5337573249856136)]\n"
     ]
    }
   ],
   "source": [
    "from gensim import corpora, models\n",
    "tfidf = models.TfidfModel(bow_corpus)\n",
    "corpus_tfidf = tfidf[bow_corpus]\n",
    "from pprint import pprint\n",
    "for doc in corpus_tfidf:\n",
    "    pprint(doc)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_num = 5\n",
    "show_feature = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = gensim.models.LdaMulticore(bow_corpus, num_topics=topic_num, id2word=dictionary, passes=20, workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 Word: 0.028*\"deal\" + 0.025*\"meeting\" + 0.012*\"hello\" + 0.010*\"netco\" + 0.009*\"information\" + 0.008*\"enron\" + 0.008*\"isda\" + 0.008*\"good\" + 0.007*\"morning\" + 0.007*\"dinner\"\n",
      "Topic: 1 Word: 0.020*\"agreement\" + 0.016*\"contract\" + 0.016*\"call\" + 0.014*\"hey\" + 0.011*\"tw\" + 0.011*\"conference\" + 0.009*\"book\" + 0.009*\"approval\" + 0.009*\"contracts\" + 0.008*\"report\"\n",
      "Topic: 2 Word: 0.019*\"power\" + 0.014*\"gas\" + 0.014*\"master\" + 0.013*\"energy\" + 0.012*\"agreement\" + 0.011*\"info\" + 0.010*\"eol\" + 0.010*\"project\" + 0.009*\"inc\" + 0.008*\"ces\"\n",
      "Topic: 3 Word: 0.017*\"lunch\" + 0.016*\"update\" + 0.013*\"...\" + 0.012*\"gisb\" + 0.012*\"letter\" + 0.010*\"checkout\" + 0.010*\"ca\" + 0.009*\"test\" + 0.008*\"e\" + 0.008*\"schedule\"\n",
      "Topic: 4 Word: 0.015*\"new\" + 0.014*\"enron\" + 0.012*\"credit\" + 0.012*\"california\" + 0.011*\"hi\" + 0.009*\"game\" + 0.009*\"fwd\" + 0.009*\"capacity\" + 0.009*\"eol\" + 0.008*\"resume\"\n"
     ]
    }
   ],
   "source": [
    "lda_model_tfidf = gensim.models.LdaMulticore(corpus_tfidf, num_topics=topic_num, id2word=dictionary, passes=2, workers=4)\n",
    "for idx, topic in lda_model_tfidf.print_topics(-1):\n",
    "    print('Topic: {} Word: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score: 0.5496178865432739\t \n",
      "Topic: 0.053*\"gas\" + 0.033*\"deal\" + 0.030*\"agreement\" + 0.020*\"report\" + 0.020*\"california\" + 0.017*\"list\" + 0.016*\"capacity\"\n",
      "\n",
      "Score: 0.30000898241996765\t \n",
      "Topic: 0.037*\"energy\" + 0.024*\"letter\" + 0.021*\"eol\" + 0.020*\"trading\" + 0.019*\"enron\" + 0.018*\"agreement\" + 0.018*\"credit\"\n",
      "\n",
      "Score: 0.05036928504705429\t \n",
      "Topic: 0.065*\"meeting\" + 0.025*\"...\" + 0.022*\"call\" + 0.019*\"conference\" + 0.012*\"lunch\" + 0.011*\"game\" + 0.010*\"management\"\n",
      "\n",
      "Score: 0.050001926720142365\t \n",
      "Topic: 0.034*\"update\" + 0.025*\"contract\" + 0.015*\"revised\" + 0.015*\"--\" + 0.013*\"dinner\" + 0.013*\"e\" + 0.012*\"final\"\n",
      "\n",
      "Score: 0.05000191181898117\t \n",
      "Topic: 0.056*\"new\" + 0.034*\"enron\" + 0.017*\"deals\" + 0.016*\"schedule\" + 0.015*\"power\" + 0.012*\"information\" + 0.011*\"book\"\n"
     ]
    }
   ],
   "source": [
    "for index, score in sorted(lda_model[bow_corpus[4310]], key=lambda tup: -1*tup[1]):\n",
    "    print(\"\\nScore: {}\\t \\nTopic: {}\".format(score, lda_model.print_topic(index, show_feature)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score: 0.7407269477844238\t \n",
      "Topic: 0.019*\"power\" + 0.014*\"gas\" + 0.014*\"master\" + 0.013*\"energy\" + 0.012*\"agreement\" + 0.011*\"info\" + 0.010*\"eol\"\n",
      "\n",
      "Score: 0.1052582785487175\t \n",
      "Topic: 0.015*\"new\" + 0.014*\"enron\" + 0.012*\"credit\" + 0.012*\"california\" + 0.011*\"hi\" + 0.009*\"game\" + 0.009*\"fwd\"\n",
      "\n",
      "Score: 0.05215754359960556\t \n",
      "Topic: 0.017*\"lunch\" + 0.016*\"update\" + 0.013*\"...\" + 0.012*\"gisb\" + 0.012*\"letter\" + 0.010*\"checkout\" + 0.010*\"ca\"\n",
      "\n",
      "Score: 0.05109405145049095\t \n",
      "Topic: 0.028*\"deal\" + 0.025*\"meeting\" + 0.012*\"hello\" + 0.010*\"netco\" + 0.009*\"information\" + 0.008*\"enron\" + 0.008*\"isda\"\n",
      "\n",
      "Score: 0.05076313763856888\t \n",
      "Topic: 0.020*\"agreement\" + 0.016*\"contract\" + 0.016*\"call\" + 0.014*\"hey\" + 0.011*\"tw\" + 0.011*\"conference\" + 0.009*\"book\"\n"
     ]
    }
   ],
   "source": [
    "for index, score in sorted(lda_model_tfidf[bow_corpus[4310]], key=lambda tup: -1*tup[1]):\n",
    "    print(\"\\nScore: {}\\t \\nTopic: {}\".format(score, lda_model_tfidf.print_topic(index, show_feature)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.4398180842399597\t Topic: 0.053*\"gas\" + 0.033*\"deal\" + 0.030*\"agreement\" + 0.020*\"report\" + 0.020*\"california\" + 0.017*\"list\" + 0.016*\"capacity\"\n",
      "Score: 0.43873241543769836\t Topic: 0.037*\"energy\" + 0.024*\"letter\" + 0.021*\"eol\" + 0.020*\"trading\" + 0.019*\"enron\" + 0.018*\"agreement\" + 0.018*\"credit\"\n",
      "Score: 0.041292134672403336\t Topic: 0.056*\"new\" + 0.034*\"enron\" + 0.017*\"deals\" + 0.016*\"schedule\" + 0.015*\"power\" + 0.012*\"information\" + 0.011*\"book\"\n",
      "Score: 0.04015404358506203\t Topic: 0.065*\"meeting\" + 0.025*\"...\" + 0.022*\"call\" + 0.019*\"conference\" + 0.012*\"lunch\" + 0.011*\"game\" + 0.010*\"management\"\n",
      "Score: 0.04000331461429596\t Topic: 0.034*\"update\" + 0.025*\"contract\" + 0.015*\"revised\" + 0.015*\"--\" + 0.013*\"dinner\" + 0.013*\"e\" + 0.012*\"final\"\n"
     ]
    }
   ],
   "source": [
    "unseen_document = ['how','pentagon','be']\n",
    "bow_vector = dictionary.doc2bow(subject_tokens[0])\n",
    "for index, score in sorted(lda_model[bow_vector], key=lambda tup: -1*tup[1]):\n",
    "    print(\"Score: {}\\t Topic: {}\".format(score, lda_model.print_topic(index, show_feature)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "['CEO','President','Vice President','Director','Employee']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-f9281d963b51>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msubject\u001b[0m \u001b[0;32min\u001b[0m \u001b[0memails_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'token_subject'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mbow_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdictionary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdoc2bow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0msubject_topics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlda_model\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbow_vector\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/gensim/models/ldamodel.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, bow, eps)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1523\u001b[0m         \"\"\"\n\u001b[0;32m-> 1524\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_document_topics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimum_phi_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mper_word_topics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1525\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'state'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'dispatcher'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseparately\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/gensim/models/ldamodel.py\u001b[0m in \u001b[0;36mget_document_topics\u001b[0;34m(self, bow, minimum_probability, minimum_phi_value, per_word_topics)\u001b[0m\n\u001b[1;32m   1328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m         \u001b[0mgamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbow\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollect_sstats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mper_word_topics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1330\u001b[0;31m         \u001b[0mtopic_dist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgamma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# normalize distribution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1331\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1332\u001b[0m         document_topics = [\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "subject_topics = []\n",
    "for subject in emails_df['token_subject']:\n",
    "    bow_vector = dictionary.doc2bow(subject)\n",
    "    subject_topics.append(dict(lda_model[bow_vector]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model.get_topic_terms(0, topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exec_email_df = emails_df[[x in exec_list for x in emails_df['sender_level']]]\n",
    "employee_email_df = emails_df[emails_df['sender_level']=='Employee']\n",
    "\n",
    "Total_Emails = list(employee_email_df['token_subject'])+list(exec_email_df['token_subject'])\n",
    "\n",
    "exec_dictionary = gensim.corpora.Dictionary(Total_Emails)\n",
    "exec_dictionary.filter_extremes(no_below=15, no_above=0.5, keep_n=100000)\n",
    "\n",
    "exec_corpus = [dictionary.doc2bow(doc) for doc in list(exec_email_df['token_subject'])]\n",
    "\n",
    "employee_corpus =[dictionary.doc2bow(doc) for doc in list(employee_email_df['token_subject'])]\n",
    "\n",
    "\n",
    "Exec_model = gensim.models.LdaMulticore(exec_corpus, num_topics=topic_num, id2word=dictionary, passes=20, workers=2)\n",
    "Employee_model = gensim.models.LdaMulticore(employee_corpus, num_topics=topic_num, id2word=dictionary, passes=20, workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdiff, annotation = Exec_model.diff(Employee_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Exec_model.top_topics(employee_corpus,topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, score in sorted(lda_model_tfidf[exec_corpus[4310]], key=lambda tup: -1*tup[1]):\n",
    "    print(\"\\nScore: {}\\t \\nTopic: {}\".format(score, lda_model_tfidf.print_topic(index, show_feature)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
